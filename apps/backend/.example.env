DATABASE_URL=postgresql://postgres:postgres@postgres:5432/mydatabase
SECRET_KEY=put-your-own
ALGORITHM=algoUses
BACKEND_CORS_ORIGINS=["http://localhost:3000", "http://localhost:5173"]

S3_ENDPOINT=minio:9000
S3_ACCESS_KEY=minio
S3_SECRET_KEY=minio123
S3_BUCKET=doclin-storage

GOOGLE_CLIENT_ID=9r55fpi39j0.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=GOCS2a5m4i0yau1VVg8lW1
GOOLE_REDIRECT=https://accounts.google.com/o/oauth2/auth
GOOGLE_TOKEN_URL=https://oauth2.googleapis.com/token
GOOGLE_USER_URL=https://www.googleapis.com/oauth2/v2/userinfo

META_ID=1894516
META_SECRET=7697d41bec6
META_REDIRECT=https://www.facebook.com/v18.0/dialog/oauth
META_TOKEN_URL=https://graph.facebook.com/v18.0/oauth/access_token
META_USER_URL=https://graph.facebook.com/me?fields=id,name,email
EMAIL=hello@gmail.com
GOOGLE_APP_PASSWORD=helloworl
SUPER_ADMIN_EMAIL=	honululu


MAX_COUNT_FOR_PREVILEGED=10
MAX_COUNT_FOR_USER=5

FRONTEND_DOMAIN=localhost
BACKEND_DOMAIN=localhost
FRONTEND_URL=http://localhost:5173/


# LLM Provider: choose one - "ollama", "gemini", or "auto"
# ---------------- LLM Provider ---------------- #
# Options: "ollama", "gemini", "auto"
LLM_PROVIDER="ollama"

# ---------------- Ollama (local) ---------------- #
OLLAMA_URL="http://ollama:11434"
OLLAMA_MODEL="mistral:7b-instruct"

# ---------------- Vector Model for embeddings ---------------- #
VECTOR_MODEL="all-mpnet-base-v2"

# ---------------- Gemini (free & paid) ---------------- #
# List of free/paid Gemini models
LLM_MODELS='["gemini-2.5-pro","gemini-2.5-flash","gemini-2.5-flash-lite","gemini-2.0-flash","gemini-2.0-flash-lite","gemini-1.5-flash","gemini-1.5-flash-8b","gemini-1.5-pro"]'
# API keys for Gemini (can rotate if multiple)
GEMINI_KEYS='["AIzaSyB6EbxY6vp_gUYwTlqMAgwMxQg"]'
LLM_API_KEY=AIzaSyB6Ebp_gUYwTlqMAgwMxQg

# ---------------- OpenRouter Free Models ---------------- #
# No keys needed here if only free tier; optional API key if required
OPENROUTER_KEY="YOUR_OPENROUTER_API_KEY"

# ---------------- DeepSeek / OpenRouter Free Models ---------------- #
# These are built into the provider manager rotation
# No need to add here, just info:
# - google/gemma-7b-it:free
# - mistralai/mistral-7b-instruct:free
# - huggingfaceh4/zephyr-7b-beta:free
# - meta-llama/llama-2-13b-chat:free
# - gryphe/mythomax-l2-13b:free
# - nousresearch/nous-hermes-llama2-13b:free
# - deepseek/deepseek-chat-v3.1:free

# ---------------- Google Colab Mistral ---------------- #
# Your Colab endpoint (Flask/FastAPI) serving Mistral 7B
COLAB_MISTRAL_URL="http://localhost:5000/generate"

# ---------------- Hugging Face GPU ---------------- #
HF_MODEL="YOUR_HF_MODEL_ID"         # e.g., "meta-llama/Llama-2-7b-chat"
HF_API_KEY="YOUR_HF_API_KEY"

# ---------------- Paid Models Toggle ---------------- #
# In production, set to False to never use paid models
ALLOW_PAID_MODELS=False

# ---------------- App URL (optional) ---------------- #
APP_URL="http://localhost:8000"

